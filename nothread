import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import time

start_time = time.time()

URL = "https://realpython.github.io/fake-jobs/"
page = requests.get(URL)
soup = BeautifulSoup(page.content, "html.parser")
results = soup.find(id="ResultsContainer")
job_elements = results.find_all("div", class_="card-content")

URLs = []
loops = 1
jobs = {'job_id': [], 'title': [], 'company': [], 'location': [], 'description': [], 'url': []}
for job_element in job_elements:
    title_element = job_element.find("h2", class_="title")
    title_element = title_element.text.strip()
    company_element = job_element.find("h3", class_="company")
    company_element = company_element.text.strip()
    location_element = job_element.find("p", class_="location")
    location_element = location_element.text.strip()
    url_element = job_element.find(attrs={'href': re.compile("^https://")}, string='Apply')
    url_element = url_element.get('href')
    jobs['job_id'].append(loops)
    jobs['title'].append(title_element)
    jobs['company'].append(company_element)
    jobs['location'].append(location_element)
    jobs['url'].append(url_element)
    loops += 1

for url in jobs['url']:
    page = requests.get(url)
    soup = BeautifulSoup(page.content, "html.parser")
    results = soup.find(id="ResultsContainer")
    job_elements = results.find_all("div", class_="content")
    for job_element in job_elements:
        description = results.find('p', string='')
        description = description.text.strip()
        jobs['description'].append(description)

df = pd.DataFrame(jobs, columns=['job_id', 'title', 'company', 'location', 'description', 'url'])
#print(df.to_string(index=False))

nothreadtime = "Without threading, this took %s seconds" % (time.time() - start_time)
print(nothreadtime)
